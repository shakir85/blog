<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Shakir</title><link>https://demo.stack.jimmycai.com/</link><description>Recent content on Shakir</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 04 Oct 2023 21:22:40 -0700</lastBuildDate><atom:link href="https://demo.stack.jimmycai.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Mounting AWS EBS volumes</title><link>https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/</link><pubDate>Wed, 04 Oct 2023 21:22:40 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/</guid><description>&lt;p>This post is designed for those new to AWS, showing the steps to attach a new EBS volume and mount it in the operating system. The goal of mounting a data volume is to maintain a clear separation between your application data and the operating-system&amp;rsquo;s data.&lt;/p>
&lt;p>Initializing EBS volumes is important also when working with Auto Scaling Groups (ASG). Auto Scaling Groups use launch templates, which contain information such as the Amazon Machine Image (AMI), SSH keys, and more, to deploy new EC2 instances during scaling events. An AMI captures the state of the root volume and any additional attached EBS volumes, including their mount points. If you attach an EBS volume, mount it to a specific directory like &lt;code>/foo&lt;/code>, and then create an AMI from that EC2 instance, the information about the attached EBS volume and its mount point will be preserved.&lt;/p>
&lt;h2 id="requrements">Requrements&lt;/h2>
&lt;ul>
&lt;li>AWS account (duh!)&lt;/li>
&lt;li>Adequate IAM permissions for EC2 and EBS (launch, attach/detach volumes).&lt;/li>
&lt;li>Basic familiarity with Linux storage mechanisms.&lt;/li>
&lt;/ul>
&lt;p>Before we start, I&amp;rsquo;d like to mention that all the steps here can be automated using the AWS CLI/SDK, or your preferred Infrastructure as Code (IaC) tool. In this instance, we&amp;rsquo;ll walk through the console setup for clarity.&lt;/p>
&lt;p>&lt;strong>Disclaimer&lt;/strong>
This post will focus on provisioning a new volume, including the formatting process. Adding a new partition to a partially used volume is beyond the scope of this blog, and following the steps below will effectively wipe all the content from the specified volume.&lt;/p>
&lt;h2 id="step-1-create-an-ebs-volume">Step 1: Create an EBS volume&lt;/h2>
&lt;p>Set your volume settings as you wish, just make sure it&amp;rsquo;s in the same AZ as the target EC2 instance.&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/ebs_console.png"
width="1003"
height="163"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/ebs_console_hu586866867ef7bb85bb64951273e36b6a_22832_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/ebs_console_hu586866867ef7bb85bb64951273e36b6a_22832_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="EBS Console"
class="gallery-image"
data-flex-grow="615"
data-flex-basis="1476px"
>&lt;/p>
&lt;h2 id="step-2-attache-the-ebs-volume-to-your-ec2-instance">Step 2: Attache the EBS volume to your EC2 instance&lt;/h2>
&lt;p>My running EC2 instance is called &lt;code>webserver&lt;/code> and I will name the volume as &lt;code>/dev/sdb&lt;/code>. This volume name should be reflected in the &lt;code>/dev&lt;/code> directory once the volume is attached successfully.&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume.png"
width="1001"
height="369"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_hu493b8332ecf777654479efac5cf5a81f_43316_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_hu493b8332ecf777654479efac5cf5a81f_43316_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Select attach"
class="gallery-image"
data-flex-grow="271"
data-flex-basis="651px"
>&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_2.png"
width="812"
height="603"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_2_hu663c1ac1ae1c854b5977df412b30f046_48454_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_2_hu663c1ac1ae1c854b5977df412b30f046_48454_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Attach and choose volume name"
class="gallery-image"
data-flex-grow="134"
data-flex-basis="323px"
>&lt;/p>
&lt;p>Once attachment is successful, you should see the new volume in the main console&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_3.png"
width="1011"
height="601"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_3_hu0acbd8792bdbac1a130b36384195c484_78046_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/attach_volume_3_hu0acbd8792bdbac1a130b36384195c484_78046_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Check attached volumes"
class="gallery-image"
data-flex-grow="168"
data-flex-basis="403px"
>&lt;/p>
&lt;h2 id="step-3-configure-the-new-volume">Step 3: Configure the new volume&lt;/h2>
&lt;p>When you add a new EBS volume to an EC2 instance in AWS, you generally need to follow similar steps as you would with on-premises servers. What we did above is just attaching a disk to a server, exactly like you would do on a physial server (or a volume to a VM in a type 1 hypervisor).&lt;/p>
&lt;p>So we need to SSH into the server and do configure the volume.&lt;/p>
&lt;h3 id="ssh-into-the-ec2-instance">SSH into the EC2 Instance&lt;/h3>
&lt;p>Make sure you have proper permissions to format, partition, and mount disks.&lt;/p>
&lt;h3 id="identify-the-new-volume">Identify the New Volume&lt;/h3>
&lt;p>Run the &lt;code>lsblk&lt;/code> (List Block Devices) command and list all disks on the system and try to identify the newly added volume&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/lsblk.png"
width="499"
height="127"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/lsblk_hua2ec3f26f00d09c1db417ec4cc684c55_13914_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/lsblk_hua2ec3f26f00d09c1db417ec4cc684c55_13914_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Showing the new volume"
class="gallery-image"
data-flex-grow="392"
data-flex-basis="942px"
>&lt;/p>
&lt;p>The &lt;code>lsblk&lt;/code> command is handy for checking disk information, including where a disk is mounted. If you look at the output above, you&amp;rsquo;ll see that our recently added volume isn&amp;rsquo;t mounted yet. You might also wonder why it&amp;rsquo;s labeled as &lt;code>xvdb&lt;/code> instead of the expected &lt;code>sdb&lt;/code>. This change is due to a new naming system in the Linux kernel. Take a look at the highlighted box in the previous screenshot for more details&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/kernel_name.png"
width="602"
height="129"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/kernel_name_hu28587522a050aa5cc12fa307dcd6fc43_16153_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/kernel_name_hu28587522a050aa5cc12fa307dcd6fc43_16153_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Volume naming notice"
class="gallery-image"
data-flex-grow="466"
data-flex-basis="1120px"
>&lt;/p>
&lt;h3 id="install-a-partition-table">Install a partition table&lt;/h3>
&lt;p>Once the disk is identified, we need to install a partition table.&lt;/p>
&lt;blockquote>
&lt;p>A partition table is a data structure on a storage device that defines the sections used for organizing data on the disk.&lt;/p>
&lt;/blockquote>
&lt;p>Run the &lt;code>fdisk&lt;/code> command and follow the instructions specfied in the code block below&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">$ sudo fdisk /dev/sdb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Welcome to fdisk (util-linux 2.37.4).
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Changes will remain in memory only, until you decide to write them.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Be careful before using the write command.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Device does not contain a recognized partition table.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Created a new DOS disklabel with disk identifier 0xf8a58774.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Command (m for help): g
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Created a new GPT disklabel (GUID: AC3E4A5C-F60F-5B42-85BB-B019A99EB6D0).
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Command (m for help): n
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Partition number (1-128, default 1):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">First sector (2048-209715166, default 2048):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-209715166, default 209715166):
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Created a new partition 1 of type &amp;#39;Linux filesystem&amp;#39; and of size 100 GiB.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Command (m for help): w
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The partition table has been altered.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Calling ioctl() to re-read partition table.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Syncing disks.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ol>
&lt;li>Enter &lt;code>g&lt;/code> and hit enter, this will create a GPT partition table.&lt;/li>
&lt;li>Enter &lt;code>n&lt;/code> and hit enter, this will create new partitio.&lt;/li>
&lt;li>Hit Enter, this will instruct &lt;code>fdisk&lt;/code> to use all the free space in the disk to the new partition.&lt;/li>
&lt;li>Enter &lt;code>w&lt;/code> and hit enter, this will write the new partition to the disk.&lt;/li>
&lt;/ol>
&lt;h3 id="check-device-partitions">Check device partitions&lt;/h3>
&lt;p>The &lt;code>/dev&lt;/code> directory is where device files are located, and devices like hard drives can have sequential names and additional entries representing partitions. For example, if you have a device named /dev/sdb, it might be the entire storage device. The partitions on that device are then represented by appending a number to the device name, such as /dev/sdb1, /dev/sdb2, and so on.&lt;/p>
&lt;p>So now we have our disk device and it has one partition (from the previous step), we should see the following devices &lt;code>/dev/sdb&lt;/code> and &lt;code>/dev/sdb1&lt;/code> in &lt;code>/dev&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/dev_dir.png"
width="846"
height="347"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/dev_dir_hu716a953821f020c08c21d6be368b7b8f_87259_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/dev_dir_hu716a953821f020c08c21d6be368b7b8f_87259_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Check the /dev directory"
class="gallery-image"
data-flex-grow="243"
data-flex-basis="585px"
>&lt;/p>
&lt;h3 id="create-a-file-system">Create a file system&lt;/h3>
&lt;p>Use the &lt;code>mkfs&lt;/code> tool to create a file system on the new partition.&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/make_filesystem.png"
width="783"
height="231"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/make_filesystem_huc8df658e6ddbd645a573ba68068df207_37616_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/make_filesystem_huc8df658e6ddbd645a573ba68068df207_37616_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Make a file system"
class="gallery-image"
data-flex-grow="338"
data-flex-basis="813px"
>&lt;/p>
&lt;p>The &lt;code>-t&lt;/code> option allows us to select the type of the file system; in this case, I will use &lt;code>ext4&lt;/code>. The &lt;code>-L&lt;/code> option can be any meaningful name for your volume. We will use that label in the &lt;code>LABEL&lt;/code> option in the next step when we mount the file system, so be sure to use a helpful name.&lt;/p>
&lt;h3 id="mount-the-new-file-system">Mount the new file system&lt;/h3>
&lt;p>Create a new directory (or use an existing one), and mount the new file system to it&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ sudo mount &lt;span class="nv">LABEL&lt;/span>&lt;span class="o">=&lt;/span>ebs001 /ebs001
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Check the mount point&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ ls /ebs001
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">lost+found
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Let&amp;rsquo;s add a file to it for testing&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/test_file.png"
width="520"
height="91"
srcset="https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/test_file_hud37cba6e2fad2ae84a226b070595f91b_8965_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/mounting-aws-ebs-volumes/test_file_hud37cba6e2fad2ae84a226b070595f91b_8965_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="Alt text"
class="gallery-image"
data-flex-grow="571"
data-flex-basis="1371px"
>&lt;/p>
&lt;p>The volume is now ready, allowing the EBS volume to easily be detached from its current EC2 instance and attached to another instance without any data loss. This volume is ideal for storing your application data, such as serving as a mount point for a Docker volume, which will keep the application data separated from the EC2 root volume at all times.&lt;/p></description></item><item><title>Understanding inodes</title><link>https://demo.stack.jimmycai.com/p/understanding-inodes/</link><pubDate>Wed, 16 Aug 2023 23:17:40 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/understanding-inodes/</guid><description>&lt;p>In Unix-like operating systems, an inode (short for &amp;ldquo;index node&amp;rdquo;) is a data structure that stores metadata about a file or directory. Each file or directory on a filesystem is associated with a unique inode which contains information such as:&lt;/p>
&lt;ul>
&lt;li>File type (regular file, directory, symbolic link, device file, etc.)&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/li>
&lt;li>Permissions (read, write, execute) for the owner, group, and others.&lt;/li>
&lt;li>Ownership (user and group) of the file.&lt;/li>
&lt;li>File size in bytes.&lt;/li>
&lt;li>Timestamps indicate when the file was accessed and modified and when the inode itself was last modified&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>.&lt;/li>
&lt;li>The number of hard links to the file&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/li>
&lt;li>Disk block pointers point to the data blocks on the storage device.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/understanding-inodes/example.png"
width="531"
height="111"
srcset="https://demo.stack.jimmycai.com/p/understanding-inodes/example_hua27a6af337a5b1ab6468d9c1e64394af_10677_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/understanding-inodes/example_hua27a6af337a5b1ab6468d9c1e64394af_10677_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="&amp;ldquo;Example: inode of an empty file&amp;rdquo;"
class="gallery-image"
data-flex-grow="478"
data-flex-basis="1148px"
>&lt;/p>
&lt;p>In this post, I&amp;rsquo;ll cover the basics of inodes – how to identify issues tied to them, and ways to troubleshoot. Keep in mind that inodes can become quite complex because they touch various parts of the filesystem.&lt;/p>
&lt;h2 id="why-the-system-needs-something-like-inodes">Why the system needs something like inodes?&lt;/h2>
&lt;p>When you create a file or directory, there is metadata associated with it, including: file name, size, type, permissions, owner, group, and more. The operating system needs something to manage the file&amp;rsquo;s metadata and the data-blocks location on the disk.&lt;/p>
&lt;p>Therefore, an inode is allocated to store the file (or directory) metadata, which allow the filesystem to properly manage file access and storage. This also make operations like finding files by name, checking permissions, and tracking file sizes easy for the OS.&lt;/p>
&lt;p>This is in general. The specific implementation and terminology may vary slightly depending on the filesystem type and the OS version.&lt;/p>
&lt;h2 id="inode-capacity">Inode capacity&lt;/h2>
&lt;p>For a filesystem, there is a quota for its inodes. The number of inodes available on a filesystem is determined during the filesystem formatting and is usually fixed number. This means that if a filesystem runs out of available inodes, you may be unable to create new files or directories, even if there is a free disk space.&lt;/p>
&lt;h3 id="in-inode-we-trust">In inode, we trust!&lt;/h3>
&lt;p>So, there is a capacity for inodes — great. But what happens if we run out of them?&lt;/p>
&lt;p>Running out of inodes (inode exhaustion) can lead to weird system failures. You might suspect that the system has run out of available inodes when a program or process fails to create a file or directory due to insufficient storage, as the error message indicates.&lt;/p>
&lt;p>Generally, it is unlikely to run out of inodes before running out of storage. But this is not impossible, especially when there are a lot of processes &lt;em>writing small files&lt;/em> constantly for a long time.&lt;/p>
&lt;p>So if you can&amp;rsquo;t create a file, and the error message states that you do not have enough space, even though you have disk space, then most likely you&amp;rsquo;ve run out of inodes.&lt;/p>
&lt;h2 id="reasons-for-inodes-exhaustion">Reasons for inodes exhaustion&lt;/h2>
&lt;p>Inode exhaustion can be caused by (but not limited to) the following factors:&lt;/p>
&lt;h3 id="small-files-and-directories">Small files and directories&lt;/h3>
&lt;p>If you have a ton of very small files and directories, each will consume an inode, which will quickly deplete the available inode pool. Regardless of whether or not there is plenty of free space on the disk.&lt;/p>
&lt;h3 id="lots-of-small-writes">Lots of small writes&lt;/h3>
&lt;p>Related to the previous point, frequent small writes, such as those caused by a lot of logging or temporary file creation, can contribute to inode exhaustion. These small writes create new inodes each time, and on the long run this can lead to a depletion of available inodes.&lt;/p>
&lt;h3 id="temporary-files">Temporary files&lt;/h3>
&lt;p>Applications that generate many temp files without cleanup can exhaust inodes. These temporary files accumulate and consume inodes if they are not frequently cleaned up.&lt;/p>
&lt;h3 id="software-builds-and-compilation">Software builds and compilation&lt;/h3>
&lt;p>Software development processes involving frequent compilation and code builds can create many temp files and directories. For example, building NodeJS apps is known for creating a ton of small files and cache. Over time, these files can contribute to inode exhaustion.&lt;/p>
&lt;h3 id="excessive-filesystem-operations">Excessive filesystem operations&lt;/h3>
&lt;p>Certain applications or scripts that frequently create, modify, or delete files and directories can lead to inode exhaustion if not properly controlled.&lt;/p>
&lt;h3 id="bundeld-servers">Bundeld Servers&lt;/h3>
&lt;p>Mail servers, content management servers (e.g., WordPress), and backup servers can also be reasons for running out of inodes. So, it&amp;rsquo;s a good practice to be aware of how these servers operate and how they interact with the file system.&lt;/p>
&lt;h2 id="how-to-fix-inode-exhaustion">How to fix inode exhaustion?&lt;/h2>
&lt;p>First, ensure whether you’re running out of inodes or not:
&lt;img src="https://demo.stack.jimmycai.com/p/understanding-inodes/check_available_inodes.png"
width="915"
height="341"
srcset="https://demo.stack.jimmycai.com/p/understanding-inodes/check_available_inodes_hu31c45bed60a1c872f961908e5df4c338_52254_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/understanding-inodes/check_available_inodes_hu31c45bed60a1c872f961908e5df4c338_52254_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="&amp;ldquo;Check available inodes&amp;rdquo;"
class="gallery-image"
data-flex-grow="268"
data-flex-basis="643px"
>&lt;/p>
&lt;p>You might think that just restarting the server would fix the problem, but that&amp;rsquo;s not necesserly right. The issue is more about the filesystem itself and not the operating system processes.&lt;/p>
&lt;p>The filesystem is persisted on disk, so a reboot does not modify the underlying filesystem properties. If the filesystem was already experiencing inode exhaustion before the reboot, the same issue will persist after the reboot.&lt;/p>
&lt;p>A reboot &lt;em>might&lt;/em> be helpful only to clear out stale or stuck processes that keep trying to write tiny files. But the reboot itself does not directly fix the underlying filesystem issue.&lt;/p>
&lt;h3 id="identify-the-issue">Identify the issue&lt;/h3>
&lt;ul>
&lt;li>Monitor filesystem usage and identify when inode exhaustion occurs.&lt;/li>
&lt;li>Review error messages, logs, and filesystem reports to determine the cause of the issue.&lt;/li>
&lt;li>If you encounter an error message indicating insufficient storage capacity, despite being certain that there is available space, it may suggest an inode issue.&lt;/li>
&lt;/ul>
&lt;h3 id="cleanup-and-delete-unnecessary-files">Cleanup and delete unnecessary files&lt;/h3>
&lt;ul>
&lt;li>Identify and delete unnecessary files. Check users&amp;rsquo; files, and ensure temporary files are cleaned up.&lt;/li>
&lt;li>Check out the &lt;code>/tpm&lt;/code> directory; applications usually use this location for scratch/cache data.&lt;/li>
&lt;li>Clear the cache of package managers by using their command line options or manually locate and remove their cache directory.&lt;/li>
&lt;li>Use tools like &lt;code>find&lt;/code> to locate and delete no longer needed files.&lt;/li>
&lt;li>Clean up old log files, and ensure &lt;code>logrotate&lt;/code> is enabled and properly configured.&lt;/li>
&lt;/ul>
&lt;h3 id="storage-optimization">Storage optimization&lt;/h3>
&lt;ul>
&lt;li>Consider compressing unused files.&lt;/li>
&lt;li>Remove redundant files.&lt;/li>
&lt;li>Avoid excessive nested directories.&lt;/li>
&lt;li>Consider using alternative storage like a NAS or other network filesystem.&lt;/li>
&lt;/ul>
&lt;h3 id="prevent-it-from-happening-again">Prevent it from happening again&lt;/h3>
&lt;ul>
&lt;li>Implement regular automated cleanup tasks.&lt;/li>
&lt;li>Reorganizing and tidying up the whole filesystem might be needed, this will need a storage expert.&lt;/li>
&lt;li>If you&amp;rsquo;re running into this problem often while compiling software in your CI/CD pipeline, you might want to think about using a Docker container to build the app and then stash away the build artifacts using Docker bind mounts or &lt;a class="link" href="https://docs.docker.com/build/exporters/" target="_blank" rel="noopener"
>docker exporter&lt;/a>. Then delete the build left overs.&lt;/li>
&lt;/ul>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>The first column of the left of the output of the &lt;code>ls -l&lt;/code> command shows file types. The &lt;code>c&lt;/code>, &lt;code>d&lt;/code> are charcter and device files, &lt;code>l&lt;/code> for symlinks, &lt;code>d&lt;/code> for directoreis and &lt;code>-&lt;/code> for files.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>Use &lt;code>stat&lt;/code> command to view when a file created, accessed or modified as well as other file info.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>Unlike symlinks, which are references to file paths, hard links directly reference the underlying data blocks of a file on disk.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>To CloudFront or not to CloudFront?</title><link>https://demo.stack.jimmycai.com/p/to-cloudfront-or-not-to-cloudfront/</link><pubDate>Tue, 01 Aug 2023 11:03:48 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/to-cloudfront-or-not-to-cloudfront/</guid><description>&lt;p>Using Amazon CloudFront to serve S3 data can be more cost-effective than serving data directly from S3 in some situations. In this post, I will discuss key points to consider when deciding to use CloudFront for serving S3 content at the edge.&lt;/p>
&lt;h2 id="data-transfer-costs">Data transfer costs&lt;/h2>
&lt;p>CloudFront can help reduce data transfer costs by caching and serving content from edge locations closer users. If your content is accessed &lt;em>frequently&lt;/em> by users from different geographic locations, CloudFront can reduce the amount of data transferred over the internet compared to serving content directly from an S3 bucket.&lt;/p>
&lt;h2 id="latency-and-performance">Latency and performance&lt;/h2>
&lt;p>CloudFront caches content at edge locations, which can significantly reduce latency and improve the overall performance for users. Users receive content from the nearest edge location, reducing the round-trip time to the original S3 bucket.&lt;/p>
&lt;h2 id="request-patterns">Request patterns&lt;/h2>
&lt;p>CloudFront can help reduce the number of requests made directly to your S3 bucket by handling a portion of the requests at the edge locations. This can be beneficial if you have a high volume of requests for the same content.&lt;/p>
&lt;h2 id="edge-location-data-processing-lambdaedge-and-cloudfront-functions">Edge location data processing: Lambda@Edge, and CloudFront Functions&lt;/h2>
&lt;p>CloudFront can also perform some data processing at the edge using &lt;a class="link" href="https://aws.amazon.com/lambda/edge/" target="_blank" rel="noopener"
>Lambda@Edge&lt;/a>, or &lt;a class="link" href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cloudfront-functions.html" target="_blank" rel="noopener"
>CloudFront Functions&lt;/a>. Lambda@Edge and CloudFront Functions allows us to add a computing element when serving content at edge. This includes customizing routing to S3 buckets, auth and auth, bot mitigation, serve specific content when your website is in maintenance mode, and overall improved user experience without modifying your website code.&lt;/p>
&lt;h2 id="consider-these-points-too">Consider these points too&lt;/h2>
&lt;p>With all the mentioed features of CloudFront for serving S3 content at edge, it&amp;rsquo;s important to consider the following aspects as well:&lt;/p>
&lt;h3 id="cloudfront-cost">CloudFront cost&lt;/h3>
&lt;p>While CloudFront can help reduce data transfer costs, it introduces its own costs based on the number of requests and data transferred from edge locations. If your data access patterns do not benefit from caching, i.e. requests always need to hit the backedn S3 bucket, then the return on investment (ROI) of using CloudFront for S3 content might not be as cost-effective as expected, and you might incur unnecessary additional costs.&lt;/p>
&lt;h3 id="cache-invalidation">Cache invalidation&lt;/h3>
&lt;p>Content Delivery Networks (CDNs) are ideal for serving static content. They are not typically a good option for dynamic content mainly due to their caching and latency handling characteristics. However, this is changing rapidly. CDN providers nowadays offer features to address these limitations as the demand for globally accessed web applications is increasing. See &lt;a class="link" href="https://aws.amazon.com/blogs/aws/amazon-cloudfront-support-for-dynamic-content" target="_blank" rel="noopener"
>this announcement&lt;/a> from AWS in 2020.&lt;/p>
&lt;p>If your data frequently changes and requires constant updates, you may need to have a good plan for managing cache invalidation and service costs.&lt;/p>
&lt;h3 id="low-volume-data-transfer">Low volume data transfer&lt;/h3>
&lt;p>For very small data-transfers, or infrequent access patterns, the cost advantage of using CloudFront for serving data from S3 might be less significant compared to fetching the data from the bucket directly.&lt;/p>
&lt;h3 id="transfer-to-origin">Transfer to origin&lt;/h3>
&lt;p>Data transfer from CloudFront to AWS services&amp;rsquo; origin is free, &lt;a class="link" href="https://aws.amazon.com/cloudfront/faqs/" target="_blank" rel="noopener"
>see the General section of CloudFront FAQ&lt;/a>. However, it&amp;rsquo;s always a good idea to consult AWS documentation to understand any cost-related matters.&lt;/p>
&lt;h3 id="consider-s3-corss-region-replication">Consider S3 Corss-Region Replication&lt;/h3>
&lt;p>If your application does not benefit from caching but you still want to keep the S3 data close to your users (for READ only ops), then consider using S3 Corss-Region Replication instead of CloudFront.&lt;/p></description></item><item><title>Firewalls: stateful vs. stateless</title><link>https://demo.stack.jimmycai.com/p/firewalls-stateful-vs.-stateless/</link><pubDate>Mon, 24 Jul 2023 19:56:52 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/firewalls-stateful-vs.-stateless/</guid><description>&lt;p>Whether it&amp;rsquo;s an on-prem firewall or in the cloud, it&amp;rsquo;s important to understand the fundamental distinctions in firewall types. In this post, I will summerize the differences between stateful and stateless filtering in simple and basic terms.&lt;/p>
&lt;h2 id="stateful-filtering">Stateful filtering&lt;/h2>
&lt;p>Stateful filtering, is a firewall technique that tracks the state of network connections and makes decisions (such as allow/deny) based on the context of those connections. When a packet passes through a stateful firewall, the firewall keeps track of the state of the connection by creating an entry in a state table to monitor the connection&amp;rsquo;s status.&lt;/p>
&lt;p>The state table contains information such as:&lt;/p>
&lt;ul>
&lt;li>Source&amp;rsquo;s IP address and port&lt;/li>
&lt;li>Destination&amp;rsquo;s IP address and port&lt;/li>
&lt;li>Connection status (e.g. established, new, related, or invalid).&lt;/li>
&lt;/ul>
&lt;p>By maintaining this state information, the firewall can &lt;strong>allow inbound traffic&lt;/strong> that is part of an outbound connection initiated from within the network. This &amp;ldquo;allow rule&amp;rdquo; does not have to be explicitly configured in the firewall to permit traffic from the destination back to the source. That&amp;rsquo;s whay they&amp;rsquo;re called &amp;ldquo;context-aware&amp;rdquo;, because this type is designed to understand the context of the conntection, where it&amp;rsquo;s coming from, where it&amp;rsquo;s going to, and who generated the connection.&lt;/p>
&lt;p>Imagine your application sending a request, and when the destination sends the response back, the firewall just goes, &amp;lsquo;Oh, I&amp;rsquo;ve got this! It&amp;rsquo;s coming from a destination that a client from my network initiated the connection with. No need to have the destination IP in the allow-list; we&amp;rsquo;re all good to go!&amp;rsquo;.&lt;/p>
&lt;p>The firewall will continue blocking traffic that does not &lt;strong>correspond to an existing connection&lt;/strong> or violates the state table rules. Security Groups on major cloud providers typically operate in a stateful manner.&lt;/p>
&lt;h3 id="advantages-of-stateful-filtering">Advantages of Stateful Filtering&lt;/h3>
&lt;ul>
&lt;li>Simplicity in implementation: No need to add an allow rule for the destination address if the connection originated from a client within the network.&lt;/li>
&lt;li>Improved security: Only allows traffic from established connections within our network.&lt;/li>
&lt;/ul>
&lt;h2 id="stateless-filtering">Stateless Filtering&lt;/h2>
&lt;p>Stateless filtering, is a firewall technique that examines individual packets without considering the context or state of the connection to which they belong. Each packet is analyzed independently based on predefined filtering rules. If a client within the network sends a request to a remote destination, the destination address must be on the firewall&amp;rsquo;s allow list, otherwise the client won&amp;rsquo;t receive a response.&lt;/p>
&lt;p>Think of it like the customs kiosks at an airport in some country. They check arrivals and departures for travelers separately. The passengers&amp;rsquo; origin does not generally impact their work rules. All they know is whether a passenger is arriving or departing and whether they are permitted to enter or leave the country based on predefined rules.&lt;/p>
&lt;p>In stateless filtering, the firewall evaluates each packet&amp;rsquo;s headers, such as source and destination IP, ports, and protocol type. If a packet matches one of the preconfigured rules, it is allowed or denied based on that rule&amp;rsquo;s criteria.&lt;/p>
&lt;p>Stateless firewalls do not maintain a state table to track connection states, meaning they do not know established connections. As a result, they cannot dynamically allow response traffic for outgoing connections or handle traffic related to established connections.&lt;/p>
&lt;p>In AWS, Network Access List (NACLs) operate in a stateless manner.&lt;/p>
&lt;h3 id="advantages-of-stateless-filtering">Advantages of Stateless Filtering&lt;/h3>
&lt;ul>
&lt;li>Efficiency. Each packet is evaluated in isolation without the overhead of maintaining a state table.&lt;/li>
&lt;li>Useful for basic traffic filtering and access control based on packet headers.&lt;/li>
&lt;/ul>
&lt;h2 id="scope-of-implementation">Scope of implementation&lt;/h2>
&lt;p>The fundamental concepts of stateful and stateless firewalls are consistent across firewall appliance manufacturers as well as cloud providers. However, the implementation of stateless and stateful firewall functionality (i.e. how they do it) can vary.&lt;/p>
&lt;p>For example, in AWS, stateful firewall functionality is implemented using Security Groups, which operate at the instance level. And stateless firewall functionality can be achieved through Network ACLs (Access Control Lists - NACLs), which operate at the subnet level.&lt;/p>
&lt;h2 id="comparison">Comparison&lt;/h2>
&lt;ul>
&lt;li>Stateful filtering is more sophisticated and provides better security by considering the state of connections. It can dynamically allow responses to outgoing traffic and handle related traffic.&lt;/li>
&lt;li>Simplicity in usage: they&amp;rsquo;re good when simpler filtering rules based on static rules are sufficient.&lt;/li>
&lt;/ul>
&lt;h2 id="finally">Finally&lt;/h2>
&lt;p>In practice, firewalls often utilize both stateful and stateless filtering at various levels, such as subnet, or gateway, to provide complete security. Stateful filtering is commonly used for connection tracking, while stateless filtering allows for quick packet evaluation.&lt;/p></description></item><item><title>Docker CMD and ENTRYPOINT differences</title><link>https://demo.stack.jimmycai.com/p/docker-cmd-and-entrypoint-differences/</link><pubDate>Sun, 16 Jul 2023 17:34:13 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/docker-cmd-and-entrypoint-differences/</guid><description>&lt;p>In this post, I will demonstrate how &lt;code>ENTRYPOINT&lt;/code> and &lt;code>CMD&lt;/code> work together, their differences, and how to redirect the runtime execution flow from &lt;code>ENTRYPOINT&lt;/code> to the &lt;code>CMD&lt;/code> where the main application&amp;rsquo;s command is executed.&lt;/p>
&lt;h2 id="the-way-entrypoint-and-cmd-work-together">The way &lt;code>ENTRYPOINT&lt;/code> and &lt;code>CMD&lt;/code> work together&lt;/h2>
&lt;p>In most cases, &lt;code>CMD&lt;/code> and &lt;code>ENTRYPOINT&lt;/code> instructions can be used interchangeably. Also, you do not have to use both of them together in every Dockerfile you develop. However, each instruction offers additional features that can help you control how you want to run your application. Before moving forward, let&amp;rsquo;s quickly review what each instruction does:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>ENTRYPOINT&lt;/code> is like the &amp;ldquo;main command&amp;rdquo; or the starting point for your container. It&amp;rsquo;s the default action the container takes when you run it. You might use &lt;code>ENTRYPOINT&lt;/code> to start a web server or run a specific application.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>CMD&lt;/code> can be used to provide additional arguments or options to the command specified in &lt;code>ENTRYPOINT&lt;/code>. It&amp;rsquo;s like saying, &amp;ldquo;When you start the container using the &lt;code>ENTRYPOINT&lt;/code> command, here are some extra args to pass to the executing app&amp;rdquo;. It is often used to pass &lt;em>default&lt;/em> arguments to &lt;code>ENTRYPOINT&lt;/code>. Note that we said: &amp;ldquo;default arguments&amp;rdquo; which we&amp;rsquo;ll explain what does that mean in a bit.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So, &lt;code>ENTRYPOINT&lt;/code> sets the main command of the container, and &lt;code>CMD&lt;/code> provides default arguments to that command. Here is an example:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> ubuntu&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">ENTRYPOINT&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;echo&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">CMD&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;Hello world&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Running a container from this Dockerfile is similar to executing &lt;code>echo &amp;quot;Hello world&amp;quot;&lt;/code> in the command line. The &lt;code>echo&lt;/code> is the main app and &lt;code>Hello world&lt;/code> is the argument. Similarly, in the Dockerfile above, the content of the &lt;code>CMD&lt;/code> instruction is passed to the &lt;code>ENTRYPOINT&lt;/code> as the default argument. when we build and run the container without arguments it will print &amp;ldquo;Hello world&amp;rdquo;:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker build -t &lt;span class="nb">test&lt;/span> .
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run &lt;span class="nb">test&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Output:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Hello world
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="overriding-cmd">Overriding &lt;code>CMD&lt;/code>&lt;/h3>
&lt;p>To override the &lt;code>CMD&lt;/code> that is defined in the Dockerfile (&lt;em>default&lt;/em> argument), you just pass the argument(s) after the image name:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker run &lt;span class="nb">test&lt;/span> &lt;span class="s1">&amp;#39;another hello world&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Output:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">another hello world
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This method also overrides the &lt;code>CMD&lt;/code> whether it&amp;rsquo;s used in combination with &lt;code>ENTRYPOINT&lt;/code> instruction or not.&lt;/p>
&lt;h3 id="overriding-entrypoint">Overriding &lt;code>ENTRYPOINT&lt;/code>&lt;/h3>
&lt;p>Given this Dockerfile:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> ubuntu&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">ENTRYPOINT&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;echo&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;Hello world&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>When you have a Dockerfile with only an &lt;code>ENTRYPOINT&lt;/code> (i.e. no &lt;code>CMD&lt;/code>), you need to use the &lt;code>--entrypoint&lt;/code> flag to override the entry-point command as the following:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># docker run --entrypoint &amp;lt;command&amp;gt; &amp;lt;image&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run --entrypoint &lt;span class="s1">&amp;#39;printenv&amp;#39;&lt;/span> &lt;span class="nb">test&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Output:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HOSTNAME=7ffd59696373
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HOME=/root
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you try to supply a command at runtime without specifying the &lt;code>--entrypoint&lt;/code> flag, Docker will treat the that command as additional arguments to the command specified in the &lt;code>ENTRYPOINT&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker run &lt;span class="nb">test&lt;/span> &lt;span class="s1">&amp;#39;printenv&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Output:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">Hello world printenv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is similar to an entry-point in Dockerfile like this: &lt;code>ENTRYPOINT [&amp;quot;echo&amp;quot;, &amp;quot;Hello world&amp;quot;, &amp;quot;printenv&amp;quot;]&lt;/code>&lt;/p>
&lt;h2 id="handing-over-execution-flow-from-entrypoint-to-cmd">Handing over execution flow from &lt;code>ENTRYPOINT&lt;/code> to &lt;code>CMD&lt;/code>&lt;/h2>
&lt;p>Consider the following Python Flask app:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> python:latest&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># RUN &amp;gt;&amp;gt;&amp;gt; install Python packages &amp;amp; configs ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># COPY &amp;gt;&amp;gt;&amp;gt; add files and executables&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">ENTRYPOINT&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;uvicorn&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">CMD&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;main:app&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;--host&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;0.0.0.0&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The uvicorn command will be executed when the container runs, and the &lt;code>CMD&lt;/code> instruction will provide the necessary arguments for the uvicorn server.&lt;/p>
&lt;p>Usually, we need a way to include runtime configurations that our Flask app expects to be available in the run environment prior to executing the main application in the entry-point (e.g. &lt;code>uvicorn&lt;/code>). These configurations could be starting a service, exporting environment variables, running a database migration script, or simply editing certain configuration files.&lt;/p>
&lt;p>This type of commands (runtime commands) cannot be included in &lt;code>RUN&lt;/code> stages, and it is an anti-pattern and honestly quite ugly to cram a lot of shell commands into the &lt;code>ENTRYPOINT&lt;/code> and/or &lt;code>CMD&lt;/code> sections.&lt;/p>
&lt;h3 id="enter-docker-enterypointsh">Enter &amp;ldquo;docker-enterypoint.sh&amp;rdquo;&lt;/h3>
&lt;p>When developing a Dockerfile, it is a common pattern to wrap various initialization commands within a shell script, conventionally named &amp;lsquo;docker-entrypoint.sh&amp;rsquo; or &amp;rsquo;entrypoint.sh&amp;rsquo; and execute it using an &lt;code>ENTRYPOINT&lt;/code> instruction prior to running the main app. The purpose of this technique is to provide a flexible way of configuring the Docker container environment &lt;em>at run time&lt;/em>.&lt;/p>
&lt;p>Since &lt;code>ENTRYPOINT&lt;/code> instruction provides run-time execution, we need to find a way to return the execution flow back the Dockerfile&amp;rsquo;s &lt;code>CMD&lt;/code> instruction to run the main application command.&lt;/p>
&lt;p>To do so, simply add an &lt;code>exec &amp;quot;@$&amp;quot;&lt;/code> statement at the very end of the shell script that is being executed by the &lt;code>ENTRYPOINT&lt;/code> (i.e. &amp;lsquo;docker-entrypoint.sh&amp;rsquo;) file.&lt;/p>
&lt;p>After adding all configuration scripts to &amp;lsquo;docker-entrypoint.sh,&amp;rsquo; we will modify the Dockerfile as follows:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> python:latest&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># RUN &amp;gt;&amp;gt;&amp;gt; install Python packages &amp;amp; configs ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># COPY &amp;gt;&amp;gt; add our app&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># ....&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># Copy the init script file to a directory in the PATH&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># You might need to `chmod +x` it too&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> docker-entrypoint.sh /usr/local/bin &lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">ENTRYPOINT&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;docker-entrypoint.sh&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">CMD&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;uvicorn&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;main:app&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;--host&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;0.0.0.0&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To visualize the process:&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/docker-cmd-and-entrypoint-differences/visual1.png"
width="1155"
height="437"
srcset="https://demo.stack.jimmycai.com/p/docker-cmd-and-entrypoint-differences/visual1_hu22bb2e668f1b020c51f48902814d7093_127716_480x0_resize_box_3.png 480w, https://demo.stack.jimmycai.com/p/docker-cmd-and-entrypoint-differences/visual1_hu22bb2e668f1b020c51f48902814d7093_127716_1024x0_resize_box_3.png 1024w"
loading="lazy"
alt="&amp;ldquo;Dockerfile example&amp;rdquo;"
class="gallery-image"
data-flex-grow="264"
data-flex-basis="634px"
>&lt;/p>
&lt;p>When we run the container, Docker will execute the &lt;code>ENTRYPOINT&lt;/code>, which contains the &amp;ldquo;docker-entrypoint.sh&amp;rdquo; script. Then, the &lt;code>exec &amp;quot;$@&amp;quot;&lt;/code> command in the &amp;ldquo;docker-entrypoint.sh&amp;rdquo; script will, in a sense, return control to the &lt;code>CMD&lt;/code>. To clarify, the exec part won&amp;rsquo;t transfer execution flow; it just expands the arguments specified in the &lt;code>CMD&lt;/code> instruction in a new process.&lt;/p>
&lt;p>Let&amp;rsquo;s break down what &lt;code>exec &amp;quot;@$&amp;quot;&lt;/code> does:&lt;/p>
&lt;ul>
&lt;li>&lt;code>exec&lt;/code> is a Linux command used to replace the current process with a new process. In this case, it ensures that &lt;code>&amp;quot;$@&amp;quot;&lt;/code> becomes the main process running in the container.&lt;/li>
&lt;li>&lt;code>&amp;quot;$@&amp;quot;&lt;/code> expands to all the command-line arguments passed to the container when it starts (e.g. expanding the content of the &lt;code>CMD&lt;/code> instruction). It preserves the exact arguments that were passed during container runtime. Also, you still can override the &lt;code>CMD&lt;/code> by specifying args on the &lt;code>docker run&lt;/code> command. Finally, note that you cannot place any commands in the &amp;lsquo;docker-entrypoint.sh&amp;rsquo; file after the exec &amp;ldquo;$@&amp;rdquo; line.&lt;/li>
&lt;/ul></description></item><item><title>Importing functions in shell scripting</title><link>https://demo.stack.jimmycai.com/p/importing-functions-in-shell-scripting/</link><pubDate>Thu, 22 Jun 2023 08:34:22 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/importing-functions-in-shell-scripting/</guid><description>&lt;p>In this post, I will show you how to &lt;em>source&lt;/em> (load) a Bash function from a local or remote source (e.g. a file in Github) into the current shell.&lt;/p>
&lt;p>In shell scripting, using the &lt;code>source&lt;/code> command (also known as the dot &amp;ldquo;&lt;code>.&lt;/code>&amp;rdquo; command) allows to read and execute commands from a script file, and load its content into your current shell. This makes all variables, functions, and aliases defined in that script file become available in the current shell session.&lt;/p>
&lt;h2 id="load-from-local-file">Load from local file&lt;/h2>
&lt;p>Similar to importing libraries in programming languages, you can organize your freqnetly used code in different files in your project directory and then load them as you need. See this example:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Project directory tree
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">├── lib/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ └── common.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">├── var/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│ └── stuff.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">│
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">└── main_script.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you want to import a function from &lt;code>root/lib/common.sh&lt;/code> to &lt;code>main_script.sh&lt;/code>, you only need to source that file:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>&lt;span class="c1"># *** main_script.sh ***&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">source&lt;/span> lib/common.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># .&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># code&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># .&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="load-from-remote-file">Load from remote file&lt;/h2>
&lt;p>To load script content into your current shell without downloading the remote file, you can &lt;code>curl&lt;/code> the content of the script and redirect it to a &lt;code>source&lt;/code> command as the following (don&amp;rsquo;t forget the &lt;code>-s&lt;/code> flag to silence curl&amp;rsquo;s download info):&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># You can use a dot `.` instead of `source` as well&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ &lt;span class="nb">source&lt;/span> &amp;lt;&lt;span class="o">(&lt;/span>curl -s https://raw.githubusercontent.com/shakir85/utils/main/print_hello&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Remote file content:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>print_hello&lt;span class="o">()&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">echo&lt;/span> &lt;span class="s2">&amp;#34;This is the boring hello world message&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>After that, you can invoke the &lt;code>print_hello&lt;/code> function from your current shell:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">$ print_hello
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">This is the boring hello world message
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This technique allows us to set environment variables, import functions, or modify the current shell&amp;rsquo;s behavior using the contents of a remote script. This is a cool trick when you do not want to persist the data of the remote script on the host or want to load functions or variables to the current working shell on the fly. The downside, though, is that if the remote content vanishes, your script could bust!&lt;/p></description></item><item><title>Helm basics</title><link>https://demo.stack.jimmycai.com/p/helm-basics/</link><pubDate>Tue, 30 May 2023 12:54:12 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/helm-basics/</guid><description>&lt;p>This post will cover the definition of Helm&amp;rsquo;s building blocks and basic commands.&lt;/p>
&lt;h2 id="why-helm">Why Helm?&lt;/h2>
&lt;p>When we intend to deploy an application to a K8s cluster, it&amp;rsquo;s important to know that Kubernetes doesn&amp;rsquo;t inherently understand our application&amp;rsquo;s requirements (and it shouldn&amp;rsquo;t).&lt;/p>
&lt;p>What I mean by that is Kubernetes doesn&amp;rsquo;t recognize that PVC &amp;ldquo;x&amp;rdquo; is associated with Deployment &amp;ldquo;y,&amp;rdquo; which, in turn, relies on Service &amp;ldquo;z&amp;rdquo;, and without these components, the application will not run as intended. All what Kubernetes knows is to manage its resources and thrive on keeping cluster&amp;rsquo;s objects alive.&lt;/p>
&lt;p>So we needed a way to &amp;ldquo;bundle&amp;rdquo; our Kubernetes application for better release management. We wanted to put the pieces together. Out API app needs a Deployment that requires a Service and we need a storage for that. So we all these parts should deployed, removed, updated, versioned, and shared together, becasue these parts represent a specific application.&lt;/p>
&lt;p>Helm is designed to know about our application. That&amp;rsquo;s why it&amp;rsquo;s called a package manager because it looks at our application&amp;rsquo;s K8s manifests as a group (package). It allows us to look at our Kubernetes application as &amp;ldquo;an application&amp;rdquo; rather than a collection of Kubernetes objects.&lt;/p>
&lt;h2 id="helm-chart">Helm Chart&lt;/h2>
&lt;p>A Helm Chart is a &lt;strong>packaged&lt;/strong>, &lt;strong>deployable unit&lt;/strong> that comprises &lt;strong>all configurations&lt;/strong> needed for deploying an application to a Kubernetes cluster.&lt;/p>
&lt;p>Let&amp;rsquo;s break this statement down:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Packaged: A Helm chart is a package for Kubernetes applications, similar to how a Debian apt package bundles software for easy installation on Linux.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Deployable unit: A Helm chart can be deployed to a K8s cluster, similar to the other K8s objects. It has all&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Includes all configuration files: Within a chart, you&amp;rsquo;ll add all the required K8s manifests (such as service, deployment, replicaset, etc.), that your application needs. Making it easy to deploy and manage our application within a Kubernetes cluster.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>By combining these three characteristics, you can deliver your application to any Kubernetes cluster of your choice easily. Not only that, but you can also share your chart (i.e. your applications) so others can deploy it to their cluster too.&lt;/p>
&lt;h2 id="helm-release">Helm Release&lt;/h2>
&lt;p>A Helm &amp;ldquo;release&amp;rdquo; is a running instance of a Helm chart. When you install a Helm chart, it generates a release with a unique name and version. You can install a chart multiple times, each will have its unique name, and optinally, you can use different variables and parameters.&lt;/p>
&lt;p>For example, when you install an Nginx chart, the &lt;em>installed instance&lt;/em> of the chart is called a &amp;ldquo;release&amp;rdquo;. You can have one or more Nginx releases deployed from the same chart; each installation has its unique name.&lt;/p>
&lt;h2 id="helm-repository">Helm Repository&lt;/h2>
&lt;p>A &amp;ldquo;repository&amp;rdquo; in Helm refers to a storage location where Helm charts are stored. Like any artifact repository, it can be accessed and shared. It can be a remote or local.You can interact with Helm repositories using the &lt;code>helm repo &amp;lt;command&amp;gt;&lt;/code> to add, update, or manage repositories.&lt;/p>
&lt;h2 id="helm-hub">Helm Hub&lt;/h2>
&lt;p>A &amp;ldquo;hub&amp;rdquo; refers to a centralized &lt;strong>platform&lt;/strong> that hosts a collection of repositores such as the default one Artifact Hub (&lt;a class="link" href="https://artifacthub.io/" target="_blank" rel="noopener"
>artifacthub.io&lt;/a>). These hubs provide a user-friendly interface for discovering and exploring Helm repositories.&lt;/p>
&lt;h3 id="helm-hub-vs-repo">Helm Hub vs. Repo&lt;/h3>
&lt;p>Think of Helm repositories like &lt;em>storage&lt;/em> places where Helm charts are stored and Helm hub is like a platform that offers a &lt;em>search&lt;/em> service to find Helm charts from different repositories. So basically, Helm Hub makes it easy to find and interact with Helm charts, while Helm repositories store the actual chart files.&lt;/p>
&lt;h2 id="commands-cheat-sheet">Commands cheat sheet&lt;/h2>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Helm works similarly to Linux package managers:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 1. You add, update, or delete a repository,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 2. Install, and delete Helm charts.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># By default, Helm uses https://artifacthub.io for charts. &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Helm deploys K8s resources, this means that Helm is aware of K8s namespaces.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Helm will always use the default namespace of the currently activated context &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># in your K8s cluster. &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Similar to kubectl, use the &amp;#39;-n&amp;#39; flag to interact with K8s namespaces &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># while working with Helm commands.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">#&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Search the default Helm hub&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm search hub &amp;lt;chartName&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add a repo to your local helm setup&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm repo add bitnami https://charts.bitnami.com/bitnami
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Refresh helm packages list&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm repo update
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Show added repos&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm repo list
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Search for a chart in the previously added repos.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># The `CHART VERSION` shows the chart&amp;#39;s version, and&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># the `APP VERSION` column shows the application&amp;#39;s version (e.g. Nginx&amp;#39;s version).&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># This command will list the latest version available in the repository.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm search repo &amp;lt;chartName&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># List all `APP VERSION` for a specific package&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm search repo --versions &amp;lt;chartName&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Install a chart:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># You can install the same chart multiple times with different names.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Chart names must be unique. A running instance of a chart is called `release`.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Sticking to a naming scheme for your releases is always a good idea.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install &lt;span class="o">[&lt;/span>specify-release-name&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>chart-name&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install my-release-1 bitnami/nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install my-release-2 bitnami/nginx -n dev-namespace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># List installed packages&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm list
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm ls
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm ls -a &lt;span class="c1"># list `all` including failing deployments&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm ls --all-namespaces
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Uninstall a chart&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm uninstall my-release-1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Download (+ unpack) the chart but don&amp;#39;t install it &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm pull --untar bitnami/wordpress
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Once downloaded, you can install the chart&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install &lt;span class="o">[&lt;/span>release-4&lt;span class="o">]&lt;/span> ./&amp;lt;chart&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install my-release ./wordpress
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Install a specific version of a chart (this is `CHART VERSION`)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install &lt;span class="o">[&lt;/span>release&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>repo/chart&lt;span class="o">]&lt;/span> --version &lt;span class="o">[&lt;/span>version&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install my-release bitnami/nginx --version 9.9.4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Upgrade a release to the latest version available in the repo.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># use `--version` followed by chart version number to upgrade to &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># a certain version.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm upgrade &lt;span class="o">[&lt;/span>release&lt;span class="o">]&lt;/span> &lt;span class="o">[&lt;/span>chart&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm upgrade my-release bitnami/nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># You can &amp;#39;downgrade&amp;#39; using the same command but with an older `--version` number&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm upgrade my-release bitnami/nginx --version 9.9.0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># The upgrade command also takes variables updating flags. &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Here, we are changing the default service type of Nginx &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># from LoadBalancer to a NodePort and the default value of &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># the port from 80 to 8181&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm upgrade my-release --set service.type&lt;span class="o">=&lt;/span>NodePort --set service.ports.http&lt;span class="o">=&lt;/span>&lt;span class="m">8181&lt;/span> bitnami/nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># To retain the previously modified values when upgrading a release&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm upgrade my-release --version 9.9.5 --reuse-values bitnami/nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Show details of a chart without installing it&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm show chart bitnami/nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Helm `get` to pull extended info about a release&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># you can get release&amp;#39;s -&amp;gt; &amp;#39;manifest&amp;#39;, &amp;#39;values&amp;#39;, &amp;#39;notes&amp;#39;, &amp;#39;hooks&amp;#39;, &amp;#39;all&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm get manifest &lt;span class="o">[&lt;/span>releaseName&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm get values &lt;span class="o">[&lt;/span>releaseName&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm get all &lt;span class="o">[&lt;/span>releaseName&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Get status of a release (deplyed, failed ...etc)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm status &lt;span class="o">[&lt;/span>release&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># List all available values in a chart without downloading it.&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># if you&amp;#39;re looking for specific flag, pipe the output to grep i.e. &amp;#39; | grep &amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm show values &lt;span class="o">[&lt;/span>repo/chart&lt;span class="o">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm show values bitnami/apache &lt;span class="p">|&lt;/span> grep replicaCount
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Then to update a default variable, use the &amp;#39;--set&amp;#39; flag&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm install apache-release bitnami/apache --set &lt;span class="nv">replicaCount&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="m">2&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Control the output using -o [options]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">helm search hub nginx-ingress -o yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Control the default gateway In a dual NIC host</title><link>https://demo.stack.jimmycai.com/p/control-the-default-gateway-in-a-dual-nic-host/</link><pubDate>Sat, 13 May 2023 21:34:49 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/control-the-default-gateway-in-a-dual-nic-host/</guid><description>&lt;p>Having multiple network interfaces on one machine can be pretty handy. It gives you network backup and helps you bounce back if the network gets a bit erratic. So, in this post, I&amp;rsquo;ll walk you through setting up a &amp;lsquo;default gateway&amp;rsquo; on one interface to handle outbound traffic (internet), while keeping the second one reserved just for LAN networking. Also, I&amp;rsquo;ll share some quirky bits I had to figure out along the way&lt;/p>
&lt;h2 id="setting-the-stage">Setting the stage&lt;/h2>
&lt;p>I have a mini PC (ThinkCentre M710q) running Debian 11. This device is equipped with two network interfaces: one is an Ethernet port, and the other is a Wi-Fi device.&lt;/p>
&lt;p>&lt;img src="https://demo.stack.jimmycai.com/p/control-the-default-gateway-in-a-dual-nic-host/25112651.jpeg"
width="256"
height="281"
srcset="https://demo.stack.jimmycai.com/p/control-the-default-gateway-in-a-dual-nic-host/25112651_hue96fc2f0dfeada5346881e6586233a22_17609_480x0_resize_q75_box.jpeg 480w, https://demo.stack.jimmycai.com/p/control-the-default-gateway-in-a-dual-nic-host/25112651_hue96fc2f0dfeada5346881e6586233a22_17609_1024x0_resize_q75_box.jpeg 1024w"
loading="lazy"
alt="&amp;ldquo;ThinkCenter M710q Mini PC&amp;rdquo;"
class="gallery-image"
data-flex-grow="91"
data-flex-basis="218px"
>&lt;/p>
&lt;p>I also have access to two totally different networks. So, this arrangement allows the host to connect to two different, publicly routable IP addresses via two different gateways. My plan is to connect use ethernet port for local networking, and use the wifi interface for internet traffic. To make this happen, we just need to make sure the host always selects the wifi-interface&amp;rsquo;s gateway as the default gateway.&lt;/p>
&lt;h2 id="gateway-and-interfaces-configuration">Gateway and interfaces configuration&lt;/h2>
&lt;p>First, make sure that each interface is connected to its corresponding network and has been assigned a DHCP IP from its respective gateway.&lt;/p>
&lt;h3 id="1-identify-the-interfaces">1. Identify the interfaces&lt;/h3>
&lt;p>Open a terminal window and run &lt;code>ip address show&lt;/code> or &lt;code>ip a&lt;/code> for short:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ ip addr
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inet 127.0.0.1/8 scope host lo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> valid_lft forever preferred_lft forever
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inet6 ::1/128 scope host
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> valid_lft forever preferred_lft forever
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2: enp0s31f6: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> link/ether 6q:4b:40:29:2x:e1 brd ff:ff:ff:ff:ff:ff
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inet 10.10.50.36/24 brd 10.10.50.255 scope global dynamic noprefixroute enp0s31f6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">3: wlp2s0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> link/ether 1a:3b:70:31:51:63 brd ff:ff:ff:ff:ff:ff
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inet 172.20.13.25/16 brd 172.20.255.255 scope global dynamic noprefixroute wlp2s0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> valid_lft 70380sec preferred_lft 70380sec
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>In the output above I have two active interfaces; both are up, and each has been assigned a DHCP IP:&lt;/p>
&lt;ol>
&lt;li>Ethernet interface: &lt;code>enp0s31f6&lt;/code>&lt;/li>
&lt;li>Wifi interface: &lt;code>wlp2s0&lt;/code>&lt;/li>
&lt;/ol>
&lt;h3 id="2-identify-the-default-gateway-for-each-interface">2. Identify the default gateway for each interface&lt;/h3>
&lt;p>We need to know each gateway&amp;rsquo;s IP address to set up the default gateway on the host. We can find that using the &lt;code>ip route&lt;/code> command&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ ip route
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">default via 10.10.50.10 dev enp0s31f6 proto dhcp metric 100
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">default via 172.20.1.1 dev wlp2s0 proto dhcp metric 600
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>From the output above, each interface has the following information&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Interface&lt;/th>
&lt;th>Gateway&lt;/th>
&lt;th>Assiged DHCP IP&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>enp0s31f6&lt;/td>
&lt;td>10.10.50.10&lt;/td>
&lt;td>10.10.50.36&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>wlp2s0&lt;/td>
&lt;td>172.20.1.1&lt;/td>
&lt;td>172.20.13.25&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="3-reset-the-default-gateway">3. Reset the default gateway&lt;/h3>
&lt;p>The operating system currently uses &lt;code>10.10.50.10&lt;/code> as the default gateway. To switch the default gateway to &lt;code>172.20.1.1&lt;/code>, we need to delete the default gateway and then set the second one as the default gateway.&lt;/p>
&lt;p>Since each gateway represents a publicly routable IP address, let&amp;rsquo;s take note of the current public IP address on the host before updating the gateways:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ curl ifconfig.me
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;Output=Network-1-Public-IPv4&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now let&amp;rsquo;s delete the current default gateway &lt;code>10.10.50.10&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ ip route del default
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Set the default gateway to the interface we want (wifi interface):&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ ip route add default via 172.20.1.1 dev wlp2s0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Check the public IP address again (it should return the second network&amp;rsquo;s public IP address):&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">user@host:~$ curl ifconfig.me
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;Output=Network-2-Public-IPv4&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="verify-gateway-change-using-tcpdump">Verify gateway change using &lt;code>tcpdump&lt;/code>&lt;/h3>
&lt;p>You can use &lt;code>tcpdump&lt;/code> to verify that the public traffic has been re-routed to the second gateway (wifi NIC).&lt;/p>
&lt;p>&lt;code>tcpdump&lt;/code> is a command line tool used to capture network traffic in real-time. It is a widely-used tool for troubleshooting networks and analyzing network activity.&lt;/p>
&lt;p>In our case, &lt;code>tcpdump&lt;/code> can capture packets that are sent and received through the wifi NIC on the secondary gateway. This allows us to gather detailed information about each packet, including the source and destination addresses. Consequently, we can determine whether the host utilizes the wifi-NIC&amp;rsquo;s gateway as the default gateway.&lt;/p>
&lt;p>Run &lt;code>tcpdump -D&lt;/code> as a root user to list active interfaces:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">root@host:~# tcpdump -D
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.enp0s31f6 [Up, Running, Connected]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2.wlp2s0 [Up, Running, Wireless, Associated]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Run &lt;code>tcpdump -i wlp2s0 -n -nn&lt;/code> and inspect the output, note that we are using the &lt;code>-i&lt;/code> flag to target the wifi interface:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">root@host# tcpdump -i wlp2s0 -n -nn
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[1] 11:54:37.300783 ARP, Reply 172.20.1.1 is-at 00:50:e8:04:5f:73, length 46
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[2] 11:54:37.300785 ARP, Reply 172.20.1.1 is-at 00:50:e8:04:5f:73, length 46
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[3] 11:54:37.300786 ARP, Reply 172.20.1.1 is-at 00:50:e8:04:5f:73, length 46
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[4] 11:54:37.300786 ARP, Reply 172.20.1.1 is-at 00:50:e8:04:5f:73, length 46
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[5] 11:54:37.529574 IP &amp;lt;Network-IP&amp;gt;.43681 &amp;gt; 146.70.172.2.18748: UDP, length 176
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[6] 11:54:37.881405 IP 146.70.172.2.18748 &amp;gt; &amp;lt;Network-IP&amp;gt;.43681: UDP, length 384
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[7] 11:54:42.530855 IP &amp;lt;Network-IP&amp;gt;.43681 &amp;gt; 146.70.172.2.18748: UDP, length 176
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[8] 11:54:42.737942 IP 146.70.172.2.18748 &amp;gt; &amp;lt;Network-IP&amp;gt;.43681: UDP, length 384
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;blockquote>
&lt;p>Note: the &lt;code>&amp;lt;Network-IP&amp;gt;&lt;/code> is the redacted wifi-NIC&amp;rsquo;s public IP address.&lt;/p>
&lt;/blockquote>
&lt;p>From the output, we can identify the following:&lt;/p>
&lt;ul>
&lt;li>Lines 1 to 4 show that the interface communicates with the default gateway we configured previously.&lt;/li>
&lt;li>Lines 5 to 8 show that the interface&amp;rsquo;s local IP and a remote destination are talking to each other.&lt;/li>
&lt;/ul>
&lt;p>Now let&amp;rsquo;s do the same thing with the ethernet interface:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-text" data-lang="text">&lt;span class="line">&lt;span class="cl">root@host# tcpdump -i wlp2s0 -n -nn
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.306031 IP 10.10.50.36.22 &amp;gt; 10.10.50.209.40122: Flags [P.], seq 1088064413:1088064609, ack 4151802530, win 501, options [nop,nop,TS val 703782894 ecr 4187823825], length 196
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.306385 IP 10.10.50.209.40122 &amp;gt; 10.10.50.36.22: Flags [.], ack 196, win 18695, options [nop,nop,TS val 4187823851 ecr 703782894], length 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.395515 IP 10.10.50.36.22 &amp;gt; 10.10.50.209.40122: Flags [P.], seq 196:568, ack 1, win 501, options [nop,nop,TS val 703782984 ecr 4187823851], length 372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.395740 IP 10.10.50.209.40122 &amp;gt; 10.10.50.36.22: Flags [.], ack 568, win 18695, options [nop,nop,TS val 4187823940 ecr 703782984], length 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.499285 IP 10.10.50.36.22 &amp;gt; 10.10.50.209.40122: Flags [P.], seq 568:916, ack 1, win 501, options [nop,nop,TS val 703783088 ecr 4187823940], length 348
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.499721 IP 10.10.50.209.40122 &amp;gt; 10.10.50.36.22: Flags [.], ack 916, win 18695, options [nop,nop,TS val 4187824044 ecr 703783088], length 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.603219 IP 10.10.50.36.22 &amp;gt; 10.10.50.209.40122: Flags [P.], seq 916:1264, ack 1, win 501, options [nop,nop,TS val 703783192 ecr 4187824044], length 348
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.603720 IP 10.10.50.209.40122 &amp;gt; 10.10.50.36.22: Flags [.], ack 1264, win 18695, options [nop,nop,TS val 4187824148 ecr 703783192], length 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">12:07:30.707004 IP 10.10.50.36.22 &amp;gt; 10.10.50.209.40122: Flags [P.], seq 1264:1612, ack 1, win 501, options [nop,nop,TS val 703783295 ecr 4187824148], length 348
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The output above may seem verbose due to an ongoing TCP communication, with tcpdump displaying all the steps involved in the TCP connection process.&lt;/p>
&lt;p>The interface&amp;rsquo;s IP: &lt;code>10.10.50.36&lt;/code> is engaged in communication with a local destination on the same subnet: &lt;code>10.10.50.209&lt;/code>, and vice versa, over port 22. (This is an active SSH tunnel from my laptop to the device.) The &lt;code>tcpdump&lt;/code> output is not showing any active WAN communication on this interface.&lt;/p>
&lt;p>Mission accomplished! Now all WAN traffic is routed through gateway &lt;code>172.20.1.1&lt;/code>, and the ethernet interface that&amp;rsquo;s connected to gateway &lt;code>10.10.50.10&lt;/code> is only available for LAN connections.&lt;/p>
&lt;h2 id="some-gotchas">Some gotchas&lt;/h2>
&lt;p>During &lt;em>boot-time network configuration&lt;/em>, a race condition is likely to occur regarding which interface the operating system will utilize to set the default gateway.&lt;/p>
&lt;p>Boot time network configuration is all about getting a host&amp;rsquo;s network interfaces ready to communicate when the OS is firing up. Basically, it&amp;rsquo;s setting up things like IP address, the network essentials, including the gateway address, so your device can link up with the network and chat with other devices. The operating system figures out the default gateway based on the first NIC that obtains an IP address and gateway info from its own gateway.&lt;/p>
&lt;p>In my experience, the OS always seems to prefer the Ethernet interface when it&amp;rsquo;s setting up the default gateway. I think this is due to the fact that Ethernet uses dedicated physical cables for communication, while the wifi interface relies on wireless signals, which can be affected by interference and signal strength. This can make wifi take a couple of seconds to catch up.&lt;/p>
&lt;p>Regardless, there are two solutions to remedy such a situation:&lt;/p>
&lt;h3 id="1-use-etcrclocal-or-systemdrc-localservice">1. Use &lt;code>/etc/rc.local&lt;/code> or &lt;code>systemd/rc-local.service&lt;/code>&lt;/h3>
&lt;p>Basically, add the &amp;ldquo;delete-gateway&amp;rdquo; -&amp;gt; &amp;ldquo;set-gateway&amp;rdquo; commands explained above to the &lt;code>/etc/rc.local&lt;/code>. The &lt;code>/etc/rc.local&lt;/code> is a script file that is executed by the Linux init system during the boot process. The commands or scripts in the file are executed with root privileges, so it is important to use caution when modifying the file.&lt;/p>
&lt;p>Note that the &lt;code>/etc/rc.local&lt;/code> file is deprecated in some Linux distributions, such as Ubuntu and Debian, in favor of &lt;code>systemd&lt;/code>. Systemd uses its own mechanism for executing scripts and services at boot time, and the equivalent of the &lt;code>/etc/rc.local&lt;/code> file in &lt;code>systemd&lt;/code> is the &lt;code>/etc/systemd/system/rc-local.service&lt;/code> file.&lt;/p>
&lt;h3 id="2-use-the-good-ol-cron">2. Use the good ol&amp;rsquo; cron&lt;/h3>
&lt;p>Add a CRON schedule to run the &amp;ldquo;delete-gateway&amp;rdquo; -&amp;gt; &amp;ldquo;set-gateway&amp;rdquo; commands. This approach might introduce some network interruption when CRON is triggered. So wrapping these commands in a shell script with some &lt;code>if&lt;/code>-&lt;code>else&lt;/code> logic would be a good idea to check if the gateway has changed during boot time before updating it.&lt;/p>
&lt;p>Example:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">SECOND_NETWORK_GATEWAY&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;172.20.1.1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CURRENT_PUBLIC_IP&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="k">$(&lt;/span>curl ifconfig.me&lt;span class="k">)&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">SECOND_NETWORK_PUBLIC_IP&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;99.99.99.99&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">INTERFACE_ID&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;wlp2s0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="o">[&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$CURRENT_PUBLIC_IP&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> !&lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$SECOND_NETWORK_PUBLIC_IP&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> &lt;span class="o">]&lt;/span> &lt;span class="p">;&lt;/span> &lt;span class="k">then&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ip route del default
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ip route add default via &lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$SECOND_NETWORK_GATEWAY&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span> dev &lt;span class="nv">$INTERFACE_ID&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">fi&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="signing-off-for-now">Signing off for now&lt;/h2>
&lt;p>And that&amp;rsquo;s a wrap for now! Until the next post, keep on exploring, learning, and enjoying Linux networking. Catch you on the flip side! 🚀👋&lt;/p></description></item><item><title>A practical approach for using Docker scratch base layer</title><link>https://demo.stack.jimmycai.com/p/a-practical-approach-for-using-docker-scratch-base-layer/</link><pubDate>Fri, 28 Apr 2023 15:23:17 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/a-practical-approach-for-using-docker-scratch-base-layer/</guid><description>&lt;p>The scratch base is a Docker&amp;rsquo;s reserved &lt;em>blank image&lt;/em>, or an empty filesystem, that acts like an empty layer to create parent images. It is like an empty canvas. It&amp;rsquo;s where you start building containers from scratch (no pun intended!), adding only what your application needs, making it super minimal. This gives us complete control over what can be shipped inside the container.&lt;/p>
&lt;p>In this post, I will show you two different ways to utilize the &amp;lsquo;scratch&amp;rsquo; base. The first part will explore how to create minimal Docker images primarily for sharing files with other images and use container hubs, like ECR and Docker Hub, as file storage. In the second part, I will discuss the advantages of using the scratch base layer for deploying single-binary applications.&lt;/p>
&lt;h2 id="sharing-files-between-images">Sharing files between images&lt;/h2>
&lt;p>When building images, Docker gives us the ability to pull files from other images (remote or local) using the &lt;code>--from=&lt;/code> option with the &lt;code>COPY&lt;/code> instruction in Dockerfile as follows:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> ubuntu:latest&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> --from&lt;span class="o">=&lt;/span>foo:1.2 /content /content&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># Other build commands ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>What&amp;rsquo;s neat about this is that it enables us to cherry-pick specific files from another image and toss them into our new image while it&amp;rsquo;s building. And the cherry on top? You can even pick files from a specific image by specifying in its tag. So if you have two tags for the image foo: &lt;code>foo:latest&lt;/code> and &lt;code>foo:1.2&lt;/code>, you can pull files from the version 1.2 on the fly.&lt;/p>
&lt;h3 id="treat-your-container-hub-as-a-remote-storage">Treat your container hub as a remote storage&lt;/h3>
&lt;p>Since we can copy files from remote images into a Dockerfile to include them in new image builds, we can actually store project files in the container registry as container images. You might wonder, why would you do that? Why not just use object storage like AWS S3 or even a Git repo to store and fetch files dynamically?&lt;/p>
&lt;p>Well, it&amp;rsquo;s just an additional option that comes with its own set of benefits:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>You don&amp;rsquo;t need to fuss with remote storage authentication especially if you&amp;rsquo;re already logged in to your container registry. You&amp;rsquo;re already authenticated, which is super handy in CI/CD pipelines.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It brings reproducibility to the table. Every image in your pipeline can fetch files from a single source (image) that the pipeline is already has access to. This consistency makes it easy to replicate builds.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>But, be aware that poorly planning how you use this approach can turn it into a dependency hill, and you might end up shooting yourself in the foot. So, use it wisely and be sure to document your approach.&lt;/p>
&lt;p>So, if your intention is to use Docker images solely for storing files, then here&amp;rsquo;s the approach you should take:&lt;/p>
&lt;p>Dockerfile content:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># Use scratch image, you don&amp;#39;t need a distro&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="s"> scratch&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># Copy all files you want to share from other images&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> somescript.sh /content&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> somearchive.tar.gz /content&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Build the image:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker build -t foo:1.2 .
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Push to remote (skip if you want the image to be local)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker push shakir85/foo:1.2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then, copy the files from the remote container registry into your Docekrfile:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="c"># This is your application image&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="s"> ubuntu:latest&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># Get files from remote image&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> --from&lt;span class="o">=&lt;/span>shakir85/project_files:latest /content /content&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># Build your image&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="c"># ...&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Although you can achieve the same result with minimal images like Alpine or Busybox, using a distro-based image solely for file storage and sharing in Docker is not as efficient as using scratch base image.&lt;/p>
&lt;h2 id="use-sctach-base-for-single-binary-containers">Use sctach base for single binary containers&lt;/h2>
&lt;p>The scratch base layer can be an excellent choice for creating single-binary containers when your application and its dependencies are entirely self-contained within a single executable file.&lt;/p>
&lt;p>When you use &lt;code>FROM scratch&lt;/code>, you start with an empty filesystem, and you can add only what is absolutely necessary for your application to run. This approach can help produce minimal container with a very small footprint because it contains only your application binary and nothing else.&lt;/p>
&lt;p>The catch is that, since the scratch layer is essentially an empty filesystem, your application must be &lt;a class="link" href="https://en.wikipedia.org/wiki/Static_build" target="_blank" rel="noopener"
>statically compiled&lt;/a>. Also, keep in mind that because your application is going to be statically compiled, a small-sized container is not guaranteed. The container&amp;rsquo;s size really depends on the type and requirements of the application and the number of libraries or dependencies that need to be included (compiled) along with the application.&lt;/p>
&lt;p>That being said, let&amp;rsquo;s take a look at this simple hello-world C code:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-c" data-lang="c">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#include&lt;/span> &lt;span class="cpf">&amp;lt;stdio.h&amp;gt;&lt;/span>&lt;span class="cp">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">int&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kt">void&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nf">printf&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s">&amp;#34;hello world&amp;#34;&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="mi">0&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Compile it using &lt;code>--static&lt;/code> flag to include the required libraries in the final executable:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">gcc -o hello --static hello.c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Create the &lt;code>Dockerfile&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-dockerfile" data-lang="dockerfile">&lt;span class="line">&lt;span class="cl">&lt;span class="k">FROM&lt;/span>&lt;span class="s"> scratch&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">COPY&lt;/span> hello /&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="err">&lt;/span>&lt;span class="k">CMD&lt;/span> &lt;span class="p">[&lt;/span> &lt;span class="s2">&amp;#34;/hello&amp;#34;&lt;/span> &lt;span class="p">]&lt;/span>&lt;span class="err">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Build the image and run the container:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker build --no-cache -t my-scratch:latest .
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run --rm my-scratch
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If we try to send an &lt;code>echo&lt;/code> command to the container, it will fail because there is no such a binary or application in the scratch container&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker run --rm my-scratch &lt;span class="nb">echo&lt;/span> hi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker: Error response from daemon: failed to create shim task: OCI runtime create failed:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">runc create failed: unable to start container process: exec:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="s2">&amp;#34;echo&amp;#34;&lt;/span>: executable file not found in &lt;span class="nv">$PATH&lt;/span>: unknown.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="bonus">Bonus&lt;/h3>
&lt;p>Say, for example, we want to add the &lt;code>echo&lt;/code> command to the scratch container. Since &lt;code>echo&lt;/code> is a compiled binary, we may think we can copy it from another parent image into the scratch image using &lt;code>COPY --from=ubuntu:latest /usr/bin/echo /&lt;/code> in the Dockerfile.&lt;/p>
&lt;p>However, since &lt;code>echo&lt;/code> is a dynamically linked binary, the &lt;code>echo&lt;/code> binary will need some dependencies in order to run. We can use the &lt;code>ldd&lt;/code> command&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> to view what libraries &lt;code>echo&lt;/code> depends on. Let&amp;rsquo;s jump into an Ubuntu container and examine that:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker run -it --rm ubuntu:latest bash
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root@cd3dd0afeb53:/# which &lt;span class="nb">echo&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">/usr/bin/echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root@cd3dd0afeb53:/# ldd /usr/bin/echo
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> linux-vdso.so.1 &lt;span class="o">(&lt;/span>0x00007ffe99d81000&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> libc.so.6 &lt;span class="o">=&lt;/span>&amp;gt; /lib/x86_64-linux-gnu/libc.so.6 &lt;span class="o">(&lt;/span>0x00007fecf34c3000&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> /lib64/ld-linux-x86-64.so.2 &lt;span class="o">(&lt;/span>0x00007fecf36f9000&lt;span class="o">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The output shows the &lt;code>echo&lt;/code> command&amp;rsquo;s dependencies that must be in the container, which without them, the &lt;code>echo&lt;/code> command will not work.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>This &lt;a class="link" href="https://www.reddit.com/r/linux/comments/ylg6rd/linux_instrumentation_part_4_ldd/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3" target="_blank" rel="noopener"
>Reddit post&lt;/a> shows some interesting facts about &lt;code>ldd&lt;/code>.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Docker containers process</title><link>https://demo.stack.jimmycai.com/p/docker-containers-process/</link><pubDate>Sat, 22 Apr 2023 11:17:28 -0700</pubDate><guid>https://demo.stack.jimmycai.com/p/docker-containers-process/</guid><description>&lt;p>A Docker container is a process, isolated from the host and other containers, running on the system using various Linux kernel features, such as namespaces and cgroups. And this is the main differentiator between VMs and containers.&lt;/p>
&lt;p>When you start a Docker container, Docker creates a new process in the host system&amp;rsquo;s process tree. Then it will apply the container&amp;rsquo;s configuration such as its file system, network settings and so on to this process.&lt;/p>
&lt;p>This makes the host OS consider a Docker container as just another process running on the system. Since the container is running as a process, we can actually use standard process monitoring tools, such as &lt;code>ps&lt;/code> and &lt;code>top&lt;/code>, to view and manage Docker.&lt;/p>
&lt;p>In this blog post, we will examine how to find and access a container&amp;rsquo;s process ID (PID) and root filesystem directly from the host machine.&lt;/p>
&lt;h2 id="getting-started">Getting Started&amp;hellip;&lt;/h2>
&lt;p>Let&amp;rsquo;s spin up a container and tinker with it&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker run -d --name nginx nginx:latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="access-container-pid">Access container PID&lt;/h2>
&lt;p>Docker stores detailed information about the container, including its image, configuration, volume, process ID, and network, in a low-level JSON object. You can use the docker inspect command, pipe the output to jq to parse the JSON object as you wish. Alternatively, you can query a scalar element by its name using Go language template syntax, as follows:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># SYNTAX: docker inspect -f &amp;#39;{{.State.Pid}}&amp;#39; &amp;lt;CONTAINER_ID|CONTAINER_NAME&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker inspect -f &lt;span class="s1">&amp;#39;{{.State.Pid}}&amp;#39;&lt;/span> nginx
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="check-the-proc-directory">Check the &lt;code>/proc&lt;/code> directory&lt;/h2>
&lt;p>In Linux, the &lt;code>/proc&lt;/code> directory is a virtual file system that provides a view of the system&amp;rsquo;s running processes. It contains files and directories that are dynamically generated by the kernel to provide information about the processes, hardware, and other system information.&lt;/p>
&lt;p>Each process running on the system has its own subdirectory under &lt;code>/proc&lt;/code>, identified by its process ID (PID). For example, if you have a process id = 12345, you&amp;rsquo;d find its subdirectory in this path: &lt;code>/proc/12345&lt;/code>. Inside the PID subdirectory (e.g. &lt;code>/proc/12345&lt;/code> in our case), you can find various files that provide information about the process, such as its memory usage, file descriptors, and more.&lt;/p>
&lt;p>So, since the Nginx container that we spun up previously is just a process, we should see a directory named after its PID in &lt;code>/proc&lt;/code>.&lt;/p>
&lt;p>Let&amp;rsquo;s re-run the above command and assign the output to a variable, amd &lt;code>ls&lt;/code> its &lt;code>proc&lt;/code> directory:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">PID&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>docker inspect -f &lt;span class="s1">&amp;#39;{{.State.Pid}}&amp;#39;&lt;/span> nginx&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ls /proc/&lt;span class="nv">$PID&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The output contains everything related to the container process. Explore the &lt;code>cgroup&lt;/code> or &lt;code>environ&lt;/code> files. Feel free to inspect the other files as well.&lt;/p>
&lt;p>Now let&amp;rsquo;s inspect the container&amp;rsquo;s &amp;ldquo;root&amp;rdquo; filesystem &lt;code>/proc/$PID/root&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">ls /proc/&lt;span class="nv">$PID&lt;/span>/root
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bin dev docker-entrypoint.sh home lib64 mnt proc run srv tmp var
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">boot docker-entrypoint.d etc lib media opt root sbin sys usr
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If we &lt;code>exec&lt;/code> into the container, we can see the same content from inside the container&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">docker &lt;span class="nb">exec&lt;/span> -it nginx sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root@ed08325bda2d:/# ls
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bin dev docker-entrypoint.sh home lib64 mnt proc run srv tmp var
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">boot docker-entrypoint.d etc lib media opt root sbin sys usr
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="manipulate-the-container-process">Manipulate the container process&lt;/h2>
&lt;p>Like any process on the host, you can control it, but with some limitations. You can see below how the container was terminated using the &lt;code>kill&lt;/code> command without interacting with the Docker daemon.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-sh" data-lang="sh">&lt;span class="line">&lt;span class="cl">ps aux &lt;span class="p">|&lt;/span> grep &lt;span class="nv">$PID&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root &lt;span class="m">8929&lt;/span> 0.0 0.0 &lt;span class="m">8936&lt;/span> &lt;span class="m">5872&lt;/span> ? Ss 11:30 0:00 nginx: master process nginx -g daemon off&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">root &lt;span class="m">9053&lt;/span> 0.0 0.0 &lt;span class="m">17864&lt;/span> &lt;span class="m">2408&lt;/span> pts/4 S+ 11:31 0:00 grep --color&lt;span class="o">=&lt;/span>auto &lt;span class="m">8929&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker ps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">522e39dfc08e nginx &lt;span class="s2">&amp;#34;/docker-entrypoint.…&amp;#34;&lt;/span> &lt;span class="m">10&lt;/span> minutes ago Up &lt;span class="m">7&lt;/span> minutes 80/tcp nginx
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">kill&lt;/span> -9 &lt;span class="nv">$PID&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker ps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>We explored how to find a container&amp;rsquo;s process ID and how to access its root filesystem from the host. Unlike virtual machines, containers are isolated processes running in the host. This approach allows Docker to provide lightweight, efficient containerization that can be easily managed and monitored using standard Linux tools. It also allows Docker to run on a wide variety of Linux systems, without requiring any special kernel modifications or configurations.&lt;/p></description></item><item><title>Archives</title><link>https://demo.stack.jimmycai.com/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://demo.stack.jimmycai.com/archives/</guid><description/></item><item><title/><link>https://demo.stack.jimmycai.com/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://demo.stack.jimmycai.com/</guid><description/></item><item><title>Search</title><link>https://demo.stack.jimmycai.com/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://demo.stack.jimmycai.com/search/</guid><description/></item></channel></rss>